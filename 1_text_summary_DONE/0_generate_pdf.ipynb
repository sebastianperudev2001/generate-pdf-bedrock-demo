{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set uá¹• a data source for your knowledge base \n",
    "\n",
    "Here is a table with the requested information:\n",
    "\n",
    "| Format                        | Extension    |\n",
    "|-------------------------------|--------------|\n",
    "| Plain text                    | .txt         |\n",
    "| Markdown                      | .md          |\n",
    "| HyperText Markup Language     | .html        |\n",
    "| Microsoft Word document       | .doc/.docx   |\n",
    "| Comma-separated values        | .csv         |\n",
    "| Microsoft Excel spreadsheet   | .xls/.xlsx   |\n",
    "| Portable Document             | .pdf         |\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "> The data is splited into **chunks**, which is an extract from a data source that is returned when the KB that it belongs to is queried \n",
    "\n",
    "### 3 types of chunks: \n",
    "\n",
    "1. **Default chunking**: By default, Amazon Bedrock automatically splits your source data into chunks, such that each chunk contains, at most, approximately 300 tokens. If a document contains less than 300 token, then it is not split any further\n",
    "2. **Fixed size chunking**: Amazon Bedrock splits your source data into chunks of the approximate size that you set.\n",
    "3. **No chunking**: Amazon Bedrock treats each file as one chunk. If you choose this option, you may want to pre-process your documents by splitting them into separate files before uploading them to an Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Create a S3 Bucket and upload content\n",
    "\n",
    "#TODO: Do it from code (this time it was uploaded directly to focus on Bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "region_name = 'us-east-1'  # Update this with your desired region\n",
    "\n",
    "brt = boto3.Session(profile_name=\"sebas\", region_name=region_name).client(service_name='bedrock-runtime')\n",
    "\n",
    "modelId = \"anthropic.claude-v2:1\"\n",
    "contentType = 'application/json'\n",
    "accept = 'application/json'\n",
    "human_prompt = \"\"\"\n",
    "Give an outline of 10 chapters for a ebook of AWS services for beginners. \n",
    "The output should be a JSON with the chapter titles and a brief description of each chapter.\n",
    "the JSON structure should be the following:\n",
    "{\n",
    "    \"chapters\": [\n",
    "        {\n",
    "            \"number\": int, \n",
    "            \"title\": string, \n",
    "            \"description\": string\n",
    "        },\n",
    "\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "body = json.dumps({\n",
    "    'prompt': f'\\n\\nHuman:{human_prompt}\\n\\nAssistant:',\n",
    "    \"max_tokens_to_sample\": 2000,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 1,\n",
    "})\n",
    "\n",
    "response = brt.invoke_model(\n",
    "    body=body, \n",
    "    modelId=modelId, \n",
    "    accept=accept, \n",
    "    contentType=contentType\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Specify the file path\n",
    "file_path = \"file.json\"\n",
    "\n",
    "# Write the response_body to the JSON file\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(response_body['completion'], file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is an outline of 10 chapters for an ebook of AWS services for beginners:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"chapters\": [\n",
      "        {\n",
      "            \"number\": 1,\n",
      "            \"title\": \"Introduction to AWS\",\n",
      "            \"description\": \"A brief overview of AWS and its key services and concepts.\"\n",
      "        },\n",
      "        {\n",
      "            \"number\": 2,\n",
      "            \"title\": \"AWS Global Infrastructure\", \n",
      "            \"description\": \"Understanding AWS regions, availability zones and edge locations.\"\n",
      "        },\n",
      "        {\n",
      "            \"number\": 3,\n",
      "            \"title\": \"AWS EC2\",\n",
      "            \"description\": \"Provisioning and managing virtual servers using Amazon Elastic Compute Cloud.\"\n",
      "        },\n",
      "        {\n",
      "            \"number\": 4,\n",
      "            \"title\": \"AWS S3\",\n",
      "            \"description\": \"Using Amazon Simple Storage Service for cloud object storage.\" \n",
      "        },\n",
      "        {\n",
      "            \"number\": 5,\n",
      "            \"title\": \"AWS Database Services\",\n",
      "            \"description\": \"Managed database options like RDS, DynamoDB and Redshift.\"\n",
      "        },\n",
      "        {\n",
      "            \"number\": 6,\n",
      "            \"title\": \"AWS Networking and Content Delivery\",\n",
      "            \"description\": \"Services like VPC, CloudFront, Route 53 and API Gateway.\"\n",
      "        },\n",
      "        {\n",
      "            \"number\": 7, \n",
      "            \"title\": \"AWS Security, Identity & Compliance\",\n",
      "            \"description\": \"IAM roles, security groups, AWS Organizations and compliance standards.\"\n",
      "        },\n",
      "        {\n",
      "            \"number\": 8,\n",
      "            \"title\": \"AWS Management Tools\", \n",
      "            \"description\": \"Monitoring, automation and optimization using CloudWatch, CloudFormation and more.\"\n",
      "        },\n",
      "        {\n",
      "            \"number\": 9,\n",
      "            \"title\": \"AWS Storage and Archiving\",\n",
      "            \"description\": \"Long-term data storage with S3 Glacier and Storage Gateway.\"\n",
      "        },\n",
      "        {\n",
      "            \"number\": 10,\n",
      "            \"title\": \"Getting Started with AWS\",\n",
      "            \"description\": \"Creating an AWS account, basics of usage billing and the free tier.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "This outlines 10 core chapters covering the fundamental AWS services and concepts for beginners, with a chapter description for each. The JSON structure matches the requested format with a chapter number, title and brief description for each chapter. Additional chapters could be added for specific workloads or integrations.\n"
     ]
    }
   ],
   "source": [
    "reply_from_claude = response_body['completion']\n",
    "print(reply_from_claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chapters': [{'number': 1, 'title': 'Introduction to AWS', 'description': 'A brief overview of AWS and its key services and concepts.'}, {'number': 2, 'title': 'AWS Global Infrastructure', 'description': 'Understanding AWS regions, availability zones and edge locations.'}, {'number': 3, 'title': 'AWS EC2', 'description': 'Provisioning and managing virtual servers using Amazon Elastic Compute Cloud.'}, {'number': 4, 'title': 'AWS S3', 'description': 'Using Amazon Simple Storage Service for cloud object storage.'}, {'number': 5, 'title': 'AWS Database Services', 'description': 'Managed database options like RDS, DynamoDB and Redshift.'}, {'number': 6, 'title': 'AWS Networking and Content Delivery', 'description': 'Services like VPC, CloudFront, Route 53 and API Gateway.'}, {'number': 7, 'title': 'AWS Security, Identity & Compliance', 'description': 'IAM roles, security groups, AWS Organizations and compliance standards.'}, {'number': 8, 'title': 'AWS Management Tools', 'description': 'Monitoring, automation and optimization using CloudWatch, CloudFormation and more.'}, {'number': 9, 'title': 'AWS Storage and Archiving', 'description': 'Long-term data storage with S3 Glacier and Storage Gateway.'}, {'number': 10, 'title': 'Getting Started with AWS', 'description': 'Creating an AWS account, basics of usage billing and the free tier.'}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Extract the JSON content\n",
    "json_start = reply_from_claude.find(\"```json\") + len(\"```json\")\n",
    "json_end = reply_from_claude.find(\"```\", json_start)\n",
    "json_content = reply_from_claude[json_start:json_end]\n",
    "\n",
    "# Remove newlines from the JSON content\n",
    "json_content = json_content.replace(\"\\n\", \"\")\n",
    "\n",
    "# Parse the JSON content into a dictionary\n",
    "data = json.loads(json_content)\n",
    "\n",
    "# Print the dictionary\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"outline.json\"\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{  \" computational_thinking\": [    {      \"id_number\": \"1\",      \"content\": \" Computational thinking is a set of skills that allows for abstract and systematic problem-solving. Due to the exponential increase in technology, many schools are implementing it in younger years. The goal is to propose a serious game to improve computational thinking. \",      \"sections\": [        \"In this work, the\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Unterminated string starting at: line 1 column 378 (char 377)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#json_data = json_data.replace(\"\\n\", \"\")\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(json_string)\n\u001b[0;32m---> 21\u001b[0m parsed_json \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#parsed_json\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 1 column 378 (char 377)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data_json = \"\\\"Here is a JSON document summarizing the text you provided:\\\\n```json\\\\n{\\\\n  \\\\\\\" computational_thinking\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"id_number\\\\\\\": \\\\\\\"1\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\" Computational thinking is a set of skills that allows for abstract and systematic problem-solving. Due to the exponential increase in technology, many schools are implementing it in younger years. The goal is to propose a serious game to improve computational thinking. \\\\\\\",\\\\n      \\\\\\\"sections\\\\\\\": [\\\\n        \\\\\\\"In this work, the\\\"\"\n",
    "#body_json\n",
    "# Parsing the JSON within the body to get the array of objects\n",
    "#parsed_json = json.loads(body_json)\n",
    "\n",
    "# Storing the array of objects in a list\n",
    "#array_of_objects = parsed_json\n",
    "\n",
    "# Print the list of objects\n",
    "#print(array_of_objects)\n",
    "\n",
    "start_index = data_json.find(\"```json\") + len(\"```json\")\n",
    "end_index = data_json.find(\"```\", start_index)\n",
    "json_data = data_json[start_index:end_index]\n",
    "json_string = json_data.replace(\"\\\\n\", \"\").replace(\"\\\\\", \"\")\n",
    "#json_data = json_data.replace(\"\\n\", \"\")\n",
    "\n",
    "print(json_string)\n",
    "#parsed_json = json.loads(json_string)\n",
    "#parsed_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
